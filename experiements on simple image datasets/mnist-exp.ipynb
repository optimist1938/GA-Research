{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4b798054",
      "metadata": {},
      "source": [
        "# GLGENN on Colored Fashion-MNIST\n",
        "\n",
        "This notebook builds a full training pipeline for a colored Fashion-MNIST dataset and trains a GLGENN model based on Clifford geometric algebra. The structure mirrors the CGENN tutorial but adapts the data embedding and model for images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2719c073",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7a769c04",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'algebra'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1833447476.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malgebra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcliffordalgebraex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCliffordAlgebraQT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtgp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQTGeometricProduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQTLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'algebra'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from algebra.cliffordalgebraex import CliffordAlgebraQT\n",
        "from layers.qtgp import QTGeometricProduct\n",
        "from layers.qtlinear import QTLinear\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "666aa908",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f185aab",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d3a299f4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Config(data_root='./data', img_size=14, batch_size=128, num_workers=0, num_epochs=12, lr=0.0003, weight_decay=0.0001, hidden_features=96, num_classes=10, train_split=0.9, palette_seed=123)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    data_root: str = \"./data\"\n",
        "    img_size: int = 14\n",
        "    batch_size: int = 128\n",
        "    num_workers: int = 0\n",
        "    num_epochs: int = 12\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    hidden_features: int = 96\n",
        "    num_classes: int = 10\n",
        "    train_split: float = 0.9\n",
        "    palette_seed: int = 123\n",
        "\n",
        "cfg = Config()\n",
        "cfg\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fff538bc",
      "metadata": {},
      "source": [
        "## Colored Fashion-MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "66d67d76",
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_palette():\n",
        "    # Distinct, moderately saturated colors in RGB\n",
        "    return torch.tensor(\n",
        "        [\n",
        "            [0.90, 0.25, 0.25],\n",
        "            [0.25, 0.75, 0.25],\n",
        "            [0.25, 0.45, 0.90],\n",
        "            [0.90, 0.65, 0.20],\n",
        "            [0.65, 0.25, 0.90],\n",
        "            [0.20, 0.85, 0.75],\n",
        "            [0.85, 0.20, 0.55],\n",
        "            [0.55, 0.55, 0.20],\n",
        "        ],\n",
        "        dtype=torch.float32,\n",
        "    )\n",
        "\n",
        "\n",
        "class ColoredFashionMNIST(Dataset):\n",
        "    def __init__(self, root, train, palette, seed=0, transform=None, download=True):\n",
        "        self.base = datasets.FashionMNIST(\n",
        "            root,\n",
        "            train=train,\n",
        "            download=download,\n",
        "            transform=transforms.ToTensor(),\n",
        "        )\n",
        "        self.palette = palette\n",
        "        self.seed = seed\n",
        "        self.transform = transform\n",
        "\n",
        "    def _color_for_index(self, idx):\n",
        "        # Deterministic color per sample to keep the dataset stable across epochs\n",
        "        g = torch.Generator().manual_seed(self.seed + idx)\n",
        "        color_idx = torch.randint(len(self.palette), (1,), generator=g).item()\n",
        "        return self.palette[color_idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.base[idx]\n",
        "        color = self._color_for_index(idx)\n",
        "        colored = img * color[:, None, None]\n",
        "        if self.transform is not None:\n",
        "            colored = self.transform(colored)\n",
        "        return colored, label\n",
        "\n",
        "\n",
        "def compute_channel_stats(loader, max_batches=200):\n",
        "    total_sum = torch.zeros(3)\n",
        "    total_sum_sq = torch.zeros(3)\n",
        "    total_count = 0\n",
        "\n",
        "    for i, (x, _) in enumerate(loader):\n",
        "        b, c, h, w = x.shape\n",
        "        total_sum += x.sum(dim=(0, 2, 3))\n",
        "        total_sum_sq += (x ** 2).sum(dim=(0, 2, 3))\n",
        "        total_count += b * h * w\n",
        "        if max_batches is not None and i + 1 >= max_batches:\n",
        "            break\n",
        "\n",
        "    mean = total_sum / total_count\n",
        "    std = (total_sum_sq / total_count - mean ** 2).sqrt()\n",
        "    return mean, std\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "add46617",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:10<00:00, 2.47MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 138kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:03<00:00, 1.25MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.24MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Approx mean: tensor([0.1627, 0.1426, 0.1435])\n",
            "Approx std: tensor([0.2153, 0.1848, 0.2011])\n",
            "Train batches: 422\n",
            "Val batches: 47\n",
            "Test batches: 79\n"
          ]
        }
      ],
      "source": [
        "palette = make_palette()\n",
        "resize = transforms.Resize((cfg.img_size, cfg.img_size), antialias=True)\n",
        "\n",
        "raw_train = ColoredFashionMNIST(\n",
        "    cfg.data_root,\n",
        "    train=True,\n",
        "    palette=palette,\n",
        "    seed=cfg.palette_seed,\n",
        "    transform=resize,\n",
        "    download=True,\n",
        ")\n",
        "raw_loader = DataLoader(raw_train, batch_size=cfg.batch_size, shuffle=False)\n",
        "\n",
        "mean, std = compute_channel_stats(raw_loader, max_batches=200)\n",
        "print(\"Approx mean:\", mean)\n",
        "print(\"Approx std:\", std)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    resize,\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    resize,\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "full_train = ColoredFashionMNIST(\n",
        "    cfg.data_root,\n",
        "    train=True,\n",
        "    palette=palette,\n",
        "    seed=cfg.palette_seed,\n",
        "    transform=train_transform,\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "test_set = ColoredFashionMNIST(\n",
        "    cfg.data_root,\n",
        "    train=False,\n",
        "    palette=palette,\n",
        "    seed=cfg.palette_seed,\n",
        "    transform=test_transform,\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "train_size = int(cfg.train_split * len(full_train))\n",
        "val_size = len(full_train) - train_size\n",
        "train_set, val_set = random_split(\n",
        "    full_train,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(SEED),\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size=cfg.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=cfg.num_workers,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n",
        "print(\"Test batches:\", len(test_loader))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e794203",
      "metadata": {},
      "source": [
        "## Sample Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "77ddcf72",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 900x300 with 12 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "fig, axes = plt.subplots(2, 6, figsize=(9, 3))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = x[i].permute(1, 2, 0)\n",
        "    img = (img * std + mean).clamp(0, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(int(y[i]))\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0fd263",
      "metadata": {},
      "source": [
        "## GLGENN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "56ca1c1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GLGBlock(nn.Module):\n",
        "    def __init__(self, algebra, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            QTLinear(algebra, in_features, out_features),\n",
        "            QTGeometricProduct(algebra, out_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class GLGClassifier(nn.Module):\n",
        "    def __init__(self, img_size, hidden_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.algebra = CliffordAlgebraQT((1.0, 1.0, 1.0))\n",
        "        self.num_tokens = img_size * img_size\n",
        "\n",
        "        self.block1 = GLGBlock(self.algebra, self.num_tokens, hidden_features)\n",
        "        self.block2 = GLGBlock(self.algebra, hidden_features, hidden_features)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_features, hidden_features),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_features, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 3, H, W]\n",
        "        b, c, h, w = x.shape\n",
        "        x = x.permute(0, 2, 3, 1).reshape(b, h * w, c)\n",
        "\n",
        "        mv = self.algebra.embed_grade(x, 1)\n",
        "        h = self.block1(mv)\n",
        "        h = torch.tanh(h)\n",
        "        h = self.block2(h)\n",
        "        h = torch.tanh(h)\n",
        "\n",
        "        # Invariant scalar part\n",
        "        scalars = h[..., 0]\n",
        "        return self.classifier(scalars)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cadf8042",
      "metadata": {},
      "source": [
        "## Training Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3cab16d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy_from_logits(logits, targets):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    return (preds == targets).float().mean().item()\n",
        "\n",
        "\n",
        "def run_epoch(model, loader, optimizer=None, clip_grad=1.0):\n",
        "    train_mode = optimizer is not None\n",
        "    model.train(train_mode)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    total_count = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        logits = model(x)\n",
        "        loss = nn.CrossEntropyLoss()(logits, y)\n",
        "\n",
        "        if train_mode:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            if clip_grad is not None:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_acc += accuracy_from_logits(logits, y) * batch_size\n",
        "        total_count += batch_size\n",
        "\n",
        "    return total_loss / total_count, total_acc / total_count\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b735d185",
      "metadata": {},
      "source": [
        "## Train the GLGENN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ef1fd45e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | train loss 0.8597 acc 0.7175 | val loss 0.5345 acc 0.8087\n",
            "Epoch 02 | train loss 0.4793 acc 0.8264 | val loss 0.4566 acc 0.8342\n",
            "Epoch 03 | train loss 0.4217 acc 0.8462 | val loss 0.4309 acc 0.8438\n",
            "Epoch 04 | train loss 0.3926 acc 0.8577 | val loss 0.3946 acc 0.8533\n",
            "Epoch 05 | train loss 0.3705 acc 0.8664 | val loss 0.3827 acc 0.8640\n",
            "Epoch 06 | train loss 0.3531 acc 0.8715 | val loss 0.3722 acc 0.8635\n",
            "Epoch 07 | train loss 0.3408 acc 0.8768 | val loss 0.3599 acc 0.8682\n",
            "Epoch 08 | train loss 0.3308 acc 0.8802 | val loss 0.3580 acc 0.8688\n",
            "Epoch 09 | train loss 0.3223 acc 0.8833 | val loss 0.3571 acc 0.8707\n",
            "Epoch 10 | train loss 0.3166 acc 0.8857 | val loss 0.3502 acc 0.8708\n",
            "Epoch 11 | train loss 0.3118 acc 0.8870 | val loss 0.3494 acc 0.8727\n",
            "Epoch 12 | train loss 0.3090 acc 0.8890 | val loss 0.3493 acc 0.8737\n",
            "Best val acc: 0.8736666663487752\n"
          ]
        }
      ],
      "source": [
        "model = GLGClassifier(\n",
        "    img_size=cfg.img_size,\n",
        "    hidden_features=cfg.hidden_features,\n",
        "    num_classes=cfg.num_classes,\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.num_epochs)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "for epoch in range(1, cfg.num_epochs + 1):\n",
        "    train_loss, train_acc = run_epoch(model, train_loader, optimizer=optimizer)\n",
        "    val_loss, val_acc = run_epoch(model, val_loader, optimizer=None)\n",
        "    scheduler.step()\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
        "        f\"val loss {val_loss:.4f} acc {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d389a71",
      "metadata": {},
      "source": [
        "## Test Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b1f3621a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss 0.3720 | test acc 0.8672\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = run_epoch(model, test_loader, optimizer=None)\n",
        "print(f\"Test loss {test_loss:.4f} | test acc {test_acc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae601d92",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
