{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14604512,"sourceType":"datasetVersion","datasetId":9328681}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/dmklee/image2sphere.git\n!git clone https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:45:18.083153Z","iopub.execute_input":"2026-01-24T14:45:18.084006Z","iopub.status.idle":"2026-01-24T14:45:19.832239Z","shell.execute_reply.started":"2026-01-24T14:45:18.083975Z","shell.execute_reply":"2026-01-24T14:45:19.831363Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'image2sphere'...\nremote: Enumerating objects: 169, done.\u001b[K\nremote: Counting objects: 100% (25/25), done.\u001b[K\nremote: Compressing objects: 100% (9/9), done.\u001b[K\nremote: Total 169 (delta 17), reused 16 (delta 16), pack-reused 144 (from 1)\u001b[K\nReceiving objects: 100% (169/169), 28.19 MiB | 39.82 MiB/s, done.\nResolving deltas: 100% (78/78), done.\nCloning into 'clifford-group-equivariant-neural-networks'...\nremote: Enumerating objects: 112, done.\u001b[K\nremote: Counting objects: 100% (45/45), done.\u001b[K\nremote: Compressing objects: 100% (22/22), done.\u001b[K\nremote: Total 112 (delta 32), reused 23 (delta 23), pack-reused 67 (from 1)\u001b[K\nReceiving objects: 100% (112/112), 349.95 KiB | 4.49 MiB/s, done.\nResolving deltas: 100% (38/38), done.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import sys\nimport os\nsys.path.append(\"/kaggle/working/image2sphere\")\n# original_path = \"/kaggle/working/clifford-group-equivariant-neural-networks\"\n# new_path = \"/kaggle/working/clifford\"\n# os.rename(original_path, new_path)\nsys.path.append(\"/kaggle/working/clifford\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:46:10.620496Z","iopub.execute_input":"2026-01-24T14:46:10.621087Z","iopub.status.idle":"2026-01-24T14:46:10.624867Z","shell.execute_reply.started":"2026-01-24T14:46:10.621063Z","shell.execute_reply":"2026-01-24T14:46:10.623980Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# !pip install -r /kaggle/working/image2sphere/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:45:40.986552Z","iopub.execute_input":"2026-01-24T14:45:40.987228Z","iopub.status.idle":"2026-01-24T14:45:40.990796Z","shell.execute_reply.started":"2026-01-24T14:45:40.987199Z","shell.execute_reply":"2026-01-24T14:45:40.989983Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# !wget ftp://cs.stanford.edu/cs/cvgl/PASCAL3D+_release1.1.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T12:20:45.099257Z","iopub.execute_input":"2026-01-24T12:20:45.099510Z","iopub.status.idle":"2026-01-24T12:23:46.267002Z","shell.execute_reply.started":"2026-01-24T12:20:45.099488Z","shell.execute_reply":"2026-01-24T12:23:46.266331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"markdown","source":"## CGENN imports","metadata":{}},{"cell_type":"code","source":"from clifford.models.modules.linear import MVLinear\nfrom clifford.models.modules.gp import SteerableGeometricProductLayer\nfrom clifford.models.modules.mvlayernorm import MVLayerNorm\nfrom clifford.models.modules.mvsilu import MVSiLU","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:46:52.246014Z","iopub.execute_input":"2026-01-24T14:46:52.246312Z","iopub.status.idle":"2026-01-24T14:46:52.256655Z","shell.execute_reply.started":"2026-01-24T14:46:52.246288Z","shell.execute_reply":"2026-01-24T14:46:52.255971Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"## I2S imports","metadata":{}},{"cell_type":"code","source":"import image2sphere.src.pascal_dataset\nfrom image2sphere.src.models import ResNet\nfrom image2sphere.src.pascal_dataset import Pascal3D\nfrom image2sphere.src.so3_utils import so3_healpix_grid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:46:27.172311Z","iopub.execute_input":"2026-01-24T14:46:27.172861Z","iopub.status.idle":"2026-01-24T14:46:39.260772Z","shell.execute_reply.started":"2026-01-24T14:46:27.172831Z","shell.execute_reply":"2026-01-24T14:46:39.260175Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"##  Other imports","metadata":{}},{"cell_type":"code","source":"import torch \nimport torch.nn as nn ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:47:34.991479Z","iopub.execute_input":"2026-01-24T14:47:34.991785Z","iopub.status.idle":"2026-01-24T14:47:34.995466Z","shell.execute_reply.started":"2026-01-24T14:47:34.991762Z","shell.execute_reply":"2026-01-24T14:47:34.994734Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"# CGENN","metadata":{}},{"cell_type":"markdown","source":"## CGENN basic blocks","metadata":{}},{"cell_type":"code","source":"class CGEBlock(nn.Module):\n    def __init__(self, algebra, in_features, out_features):\n        super().__init__()\n\n        self.layers = nn.Sequential(\n            MVLinear(algebra, in_features, out_features),\n            MVSiLU(algebra, out_features),\n            SteerableGeometricProductLayer(algebra, out_features),\n            MVLayerNorm(algebra, out_features)\n        )\n\n    def forward(self, input):\n        # [batch_size, in_features, 2**d] -> [batch_size, out_features, 2**d]\n        return self.layers(input)\n\nclass CGEMLP(nn.Module):\n    def __init__(self, algebra, in_features, hidden_features, out_features, n_layers=2):\n        super().__init__()\n\n        layers = []\n        for i in range(n_layers - 1):\n            layers.append(\n                CGEBlock(algebra, in_features, hidden_features)\n            )\n            in_features = hidden_features\n\n        layers.append(\n            CGEBlock(algebra, hidden_features, out_features)\n        )\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, input):\n        return self.layers(input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:47:37.060712Z","iopub.execute_input":"2026-01-24T14:47:37.061048Z","iopub.status.idle":"2026-01-24T14:47:37.067123Z","shell.execute_reply.started":"2026-01-24T14:47:37.061022Z","shell.execute_reply":"2026-01-24T14:47:37.066492Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"## CGENN model","metadata":{}},{"cell_type":"code","source":"class EquvariantCGENN(nn.Module):\n\n    def __init__(self, in_features, hidden_features, out_features):\n        super().__init__()\n        self.cgemlp = CGEMLP(ca, in_features, hidden_features, hidden_features)\n        self.mlp = nn.Sequential(\n            nn.Linear(hidden_features, hidden_features),\n            nn.ReLU(),\n            nn.Linear(hidden_features, hidden_features),\n            nn.ReLU(),\n            nn.Linear(hidden_features, out_features)\n        )\n\n    def forward(self, input):\n        h = self.cgemlp(input)\n        # Index the hidden states at 0 to get the invariants, and let a regular MLP do the final processing.\n        return self.mlp(h[..., 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-24T14:47:39.738047Z","iopub.execute_input":"2026-01-24T14:47:39.738371Z","iopub.status.idle":"2026-01-24T14:47:39.743538Z","shell.execute_reply.started":"2026-01-24T14:47:39.738346Z","shell.execute_reply":"2026-01-24T14:47:39.742985Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# Final models","metadata":{}},{"cell_type":"code","source":"class IGA2S(nn.Module):\n    def __init__(\n        self, \n        num_classes, # provided as part of the input\n        train_grid_rec_level,\n        eval_grid_rec_level,\n        size=50, \n        pretrained=True,\n        global_pooling=True,\n        hidden_dim\n    ):\n        \n        self.encoder = ResNet(size, pretrained, global_pooling)\n\n        train_grid = so3.healpix_grid(rec_level=train_grid_rec_level)\n        self.register_buffer('train_rotmats', o3.angles_to_matrix(*train_grid))\n        \n\n        eval_grid = so3.healpix_grid(rec_level=eval_grid_rec_level)\n        self.register_buffer('eval_rotmats', o3.angles_to_matrix(*eval_grid))\n\n        input_dim = self.encoder.output_shape[0]\n        self.equiv = EquvariantCGENN(input_dim + num_classes, hidden_dim, )\n        \n        \n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model 1: ResNet + CGENN head","metadata":{}},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Data prep","metadata":{}},{"cell_type":"markdown","source":"## Training & Evaluation functions","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}}]}