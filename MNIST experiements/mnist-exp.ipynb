{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4b798054",
      "metadata": {},
      "source": [
        "# GLGENN on Colored Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "205ad0ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc76af27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\", line 97, in mount\n",
            "    return _mount(\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\", line 134, in _mount\n",
            "    _message.blocking_request(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\", line 173, in blocking_request\n",
            "    request_id = send_request(\n",
            "                 ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\", line 117, in send_request\n",
            "    instance = ipython.get_kernelapp()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_ipython.py\", line 28, in get_kernelapp\n",
            "    return get_ipython().kernel.parent\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'kernel'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a769c04",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms.v2 as v2\n",
        "\n",
        "from glgenn.algebra.cliffordalgebraex import CliffordAlgebraQT\n",
        "from glgenn.algebra.cliffordalgebra import CliffordAlgebra\n",
        "from glgenn.layers.qtgp import QTGeometricProduct\n",
        "from glgenn.layers.qtlinear import QTLinear\n",
        "from glgenn.layers.qtnorm import QTNormalization\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "666aa908",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x10c8664d0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fff538bc",
      "metadata": {},
      "source": [
        "## Dataloader (Colored Fashion MNIST + GA embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "66d67d76",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CliffordFashionedMnist(Dataset):\n",
        "    def __init__(self, root, train=True, download=True, d=5):\n",
        "        self.metric = [1] * d\n",
        "        self.ca = CliffordAlgebraQT(self.metric)\n",
        "        self.d = d\n",
        "        self.h, self.w = 28, 28\n",
        "        self.post_transforms = v2.Compose([\n",
        "            v2.ToImage(),\n",
        "            v2.ToDtype(torch.float32, scale=True),\n",
        "            v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        self.data = datasets.FashionMNIST(root, train=train, download=download)\n",
        "\n",
        "        y_coords, x_coords = torch.meshgrid(\n",
        "            torch.linspace(-1, 1, self.h),\n",
        "            torch.linspace(-1, 1, self.w),\n",
        "            indexing=\"ij\"\n",
        "        )\n",
        "        self.grid = torch.stack([x_coords, y_coords], dim=0) # [2, 28, 28]\n",
        "\n",
        "    def _colorize_random(self, img):\n",
        "        img_np = np.array(img) \n",
        "        factors = np.random.uniform(0.2, 1.0, 3)\n",
        "        color_img = np.stack([img_np * f for f in factors], axis=-1).astype(np.uint8) # [28, 28, 3]\n",
        "        return color_img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img_raw, label = self.data[idx]\n",
        "        img_colored = self._colorize_random(img_raw) # [3, 28, 28]\n",
        "        img_tensor = self.post_transforms(img_colored) \n",
        "        v_full = torch.cat([self.grid, img_tensor], dim=0) # [5, 28, 28]\n",
        "        v_full = v_full.permute(1, 2, 0) # [28, 28, 5]\n",
        "        x_mv = self.ca.embed_grade(v_full, 1)  # [28, 28, 2 ** 5]\n",
        "        return x_mv, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b263a519",
      "metadata": {},
      "source": [
        "### Prepare: MVSiLU from CGENN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a0561b75",
      "metadata": {},
      "outputs": [],
      "source": [
        "def unsqueeze_like(tensor: torch.Tensor, like: torch.Tensor, dim=0):\n",
        "    \"\"\"\n",
        "    Unsqueeze last dimensions of tensor to match another tensor's number of dimensions.\n",
        "\n",
        "    Args:\n",
        "        tensor (torch.Tensor): tensor to unsqueeze\n",
        "        like (torch.Tensor): tensor whose dimensions to match\n",
        "        dim: int: starting dim, default: 0.\n",
        "    \"\"\"\n",
        "    n_unsqueezes = like.ndim - tensor.ndim\n",
        "    if n_unsqueezes < 0:\n",
        "        raise ValueError(f\"tensor.ndim={tensor.ndim} > like.ndim={like.ndim}\")\n",
        "    elif n_unsqueezes == 0:\n",
        "        return tensor\n",
        "    else:\n",
        "        return tensor[dim * (slice(None),) + (None,) * n_unsqueezes]\n",
        "\n",
        "class MVSiLU(nn.Module):\n",
        "    def __init__(self, algebra, channels, invariant=\"mag2\", exclude_dual=False):\n",
        "        super().__init__()\n",
        "        self.algebra = algebra\n",
        "        self.channels = channels\n",
        "        self.exclude_dual = exclude_dual\n",
        "        self.invariant = invariant\n",
        "        self.a = nn.Parameter(torch.ones(1, channels, algebra.dim + 1))\n",
        "        self.b = nn.Parameter(torch.zeros(1, channels, algebra.dim + 1))\n",
        "\n",
        "        if invariant == \"norm\":\n",
        "            self._get_invariants = self._norms_except_scalar\n",
        "        elif invariant == \"mag2\":\n",
        "            self._get_invariants = self._mag2s_except_scalar\n",
        "        else:\n",
        "            raise ValueError(f\"Invariant {invariant} not recognized.\")\n",
        "\n",
        "    def _norms_except_scalar(self, input):\n",
        "        return self.algebra.norms(input, grades=self.algebra.grades[1:])\n",
        "\n",
        "    def _mag2s_except_scalar(self, input):\n",
        "        return self.algebra.qs(input, grades=self.algebra.grades[1:])\n",
        "\n",
        "    def forward(self, input):\n",
        "        norms = self._get_invariants(input)\n",
        "        norms = torch.cat([input[..., :1], *norms], dim=-1)\n",
        "        a = unsqueeze_like(self.a, norms, dim=2)\n",
        "        b = unsqueeze_like(self.b, norms, dim=2)\n",
        "        norms = a * norms + b\n",
        "        norms = norms.repeat_interleave(self.algebra.subspaces, dim=-1)\n",
        "        return torch.sigmoid(norms) * input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0fd263",
      "metadata": {},
      "source": [
        "## Model \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "35f627f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CGEBlock(nn.Module):\n",
        "    def __init__(self, algebra, in_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            QTLinear(algebra, in_features, out_features),\n",
        "            MVSiLU(algebra, out_features),\n",
        "            QTGeometricProduct(algebra, out_features),\n",
        "            QTNormalization(algebra, out_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        # [batch_size, in_features, 2**d] -> [batch_size, out_features, 2**d]\n",
        "        return self.layers(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2cde10ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CGEMLP(nn.Module):\n",
        "    def __init__(self, algebra, in_features, hidden_features, out_features, n_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        for i in range(n_layers - 1):\n",
        "            layers.append(\n",
        "                CGEBlock(algebra, in_features, hidden_features)\n",
        "            )\n",
        "            in_features = hidden_features\n",
        "\n",
        "        layers.append(\n",
        "            CGEBlock(algebra, hidden_features, out_features)\n",
        "        )\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.layers(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6d99d97e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CliffordFashionModel(nn.Module):\n",
        "    def __init__(self, ca, in_channels=1, hidden_channels=16, out_classes=10):\n",
        "        super().__init__()\n",
        "        self.ca = ca\n",
        "        self.cge_part = CGEMLP(ca, in_channels, hidden_channels, hidden_channels)\n",
        "        self.activation = MVSiLU(ca, hidden_channels)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_channels, out_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, h, w, mv_dim = x.shape\n",
        "        print(f\"Debug: Input shape {x.shape}\") # Проверка входящего размера\n",
        "        \n",
        "        x = x.view(batch_size * h * w, 1, mv_dim)\n",
        "        print(f\"Debug: After view {x.shape}\")\n",
        "        \n",
        "        # Проверяем проход через основной блок\n",
        "        print(\"Debug: Entering CGEMLP...\")\n",
        "        h_out = self.cge_part(x) \n",
        "        print(\"Debug: CGEMLP finished.\")\n",
        "        \n",
        "        h_out = self.activation(h_out)\n",
        "        invariants = h_out[..., 0]\n",
        "        invariants = invariants.view(batch_size, h * w, -1)\n",
        "        \n",
        "        print(\"Debug: Global average pooling...\")\n",
        "        pooled = invariants.mean(dim=1)\n",
        "        \n",
        "        return self.classifier(pooled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ef6d7e8",
      "metadata": {},
      "source": [
        "## Training & Evaluating "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6457b1c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "def print_memory_stats(step_name):\n",
        "    process = psutil.Process()\n",
        "    ram_usage = process.memory_info().rss / 1024 / 1024  # в МБ\n",
        "    vram_stats = \"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024 / 1024\n",
        "        reserved = torch.cuda.memory_reserved() / 1024 / 1024\n",
        "        vram_stats = f\" | VRAM Allocated: {allocated:.1f}MB, Reserved: {reserved:.1f}MB\"\n",
        "    print(f\"[{step_name}] RAM: {ram_usage:.1f}MB{vram_stats}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc1e03c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "Debug: Testing DataLoader...\n",
            "Debug: Batch shape: torch.Size([64, 28, 28, 32])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   0%|          | 0/938 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Batch 0 Start ---\n",
            "[Before Loading to Device] RAM: 258.5MB\n",
            "[After Loading to Device] RAM: 258.7MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 734.4MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   0%|          | 1/938 [00:35<9:13:32, 35.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 1329.8MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 1 Start ---\n",
            "[Before Loading to Device] RAM: 1259.5MB\n",
            "[After Loading to Device] RAM: 1259.5MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 1013.8MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   0%|          | 2/938 [01:17<10:13:21, 39.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 917.1MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 2 Start ---\n",
            "[Before Loading to Device] RAM: 825.6MB\n",
            "[After Loading to Device] RAM: 825.5MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 783.6MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   0%|          | 3/938 [02:00<10:40:50, 41.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 1047.9MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 3 Start ---\n",
            "[Before Loading to Device] RAM: 905.8MB\n",
            "[After Loading to Device] RAM: 905.8MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 836.0MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   0%|          | 4/938 [02:40<10:31:24, 40.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 1537.3MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 4 Start ---\n",
            "[Before Loading to Device] RAM: 1569.2MB\n",
            "[After Loading to Device] RAM: 1569.2MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 864.4MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   1%|          | 5/938 [03:23<10:43:33, 41.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 1314.3MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 5 Start ---\n",
            "[Before Loading to Device] RAM: 1187.8MB\n",
            "[After Loading to Device] RAM: 1187.8MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 834.9MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   1%|          | 6/938 [03:55<9:56:41, 38.41s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 2626.2MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 6 Start ---\n",
            "[Before Loading to Device] RAM: 2651.2MB\n",
            "[After Loading to Device] RAM: 2651.2MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 1019.8MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   1%|          | 7/938 [04:30<9:36:22, 37.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 1303.4MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 7 Start ---\n",
            "[Before Loading to Device] RAM: 1222.7MB\n",
            "[After Loading to Device] RAM: 1222.7MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n",
            "Debug: CGEMLP finished.\n",
            "Debug: Global average pooling...\n",
            "[After Forward pass] RAM: 695.1MB\n",
            "Starting Backward pass...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   1%|          | 8/938 [05:04<9:20:33, 36.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[After Backward pass] RAM: 1193.1MB\n",
            "--- Batch End ---\n",
            "\n",
            "\n",
            "--- Batch 8 Start ---\n",
            "[Before Loading to Device] RAM: 937.7MB\n",
            "[After Loading to Device] RAM: 937.3MB\n",
            "Starting Forward pass...\n",
            "Debug: Input shape torch.Size([64, 28, 28, 32])\n",
            "Debug: After view torch.Size([50176, 1, 32])\n",
            "Debug: Entering CGEMLP...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   1%|          | 8/938 [05:11<10:02:55, 38.90s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Замеряем Forward pass по частям\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Forward pass...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m print_memory_stats(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter Forward pass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mCliffordFashionModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Проверяем проход через основной блок\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebug: Entering CGEMLP...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m h_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcge_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebug: CGEMLP finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m h_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(h_out)\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mCGEMLP.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mCGEBlock.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# [batch_size, in_features, 2**d] -> [batch_size, out_features, 2**d]\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/Desktop/GA-Research/MNIST experiements/glgenn/layers/qtgp.py:54\u001b[0m, in \u001b[0;36mQTGeometricProduct.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m input_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization(input_right)\n\u001b[1;32m     53\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_weight()\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbni, nijk, bnk -> bnj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_right\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/GA-Research/.venv/lib/python3.9/site-packages/torch/functional.py:422\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    424\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == 'cuda':\n",
        "    torch.set_default_device('cuda')\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "d = 5\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "\n",
        "ca = CliffordAlgebraQT([1] * d)\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    if hasattr(ca, 'qt_geometric_product_paths'):\n",
        "        ca.qt_geometric_product_paths = ca.qt_geometric_product_paths.to(device)\n",
        "\n",
        "full_dataset = CliffordFashionedMnist(root='./data', train=True, download=True)\n",
        "train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True, generator=torch.Generator(device='cpu'))\n",
        "\n",
        "print(\"Debug: Testing DataLoader...\")\n",
        "test_batch, test_labels = next(iter(train_loader))\n",
        "print(f\"Debug: Batch shape: {test_batch.shape}\")\n",
        "\n",
        "model = CliffordFashionModel(ca, in_channels=1, hidden_channels=16).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
        "    \n",
        "    for batch_idx, (images, labels) in enumerate(pbar):\n",
        "        print(f\"\\n--- Batch {batch_idx} Start ---\")\n",
        "        print_memory_stats(\"Before Loading to Device\")\n",
        "        \n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        print_memory_stats(\"After Loading to Device\")\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Замеряем Forward pass по частям\n",
        "        print(\"Starting Forward pass...\")\n",
        "        outputs = model(images)\n",
        "        print_memory_stats(\"After Forward pass\")\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        print(\"Starting Backward pass...\")\n",
        "        loss.backward()\n",
        "        print_memory_stats(\"After Backward pass\")\n",
        "        \n",
        "        optimizer.step()\n",
        "        print(\"--- Batch End ---\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24b2ebf6",
      "metadata": {},
      "source": [
        "## Building standard models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a6a2f31",
      "metadata": {},
      "source": [
        "## Stress tests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe29a3d",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "265be756",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
