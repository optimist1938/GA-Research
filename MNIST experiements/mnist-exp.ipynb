{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14509027,"sourceType":"datasetVersion","datasetId":9266920}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GLGENN on simple CV tasks","metadata":{"id":"4b798054"}},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())","metadata":{"id":"205ad0ff","outputId":"6ca1eb0c-bf26-4395-a75d-52c4113fd8b0","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:49.885919Z","iopub.execute_input":"2026-01-17T13:54:49.886634Z","iopub.status.idle":"2026-01-17T13:54:51.722432Z","shell.execute_reply.started":"2026-01-17T13:54:49.886600Z","shell.execute_reply":"2026-01-17T13:54:51.721484Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.chdir('/')\nif not os.path.exists(\"/clifford-group-equivariant-neural-networks\"):\n    !git clone https://github.com/DavidRuhe/clifford-group-equivariant-neural-networks.git\nos.chdir(\"/clifford-group-equivariant-neural-networks\")","metadata":{"id":"fpDjl70Lp7uP","outputId":"b561ef04-c084-4244-ca2e-29514a830907","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:51.725972Z","iopub.execute_input":"2026-01-17T13:54:51.726316Z","iopub.status.idle":"2026-01-17T13:54:51.731156Z","shell.execute_reply.started":"2026-01-17T13:54:51.726280Z","shell.execute_reply":"2026-01-17T13:54:51.730460Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import sys\nmodule_path = os.path.abspath('/kaggle/input')\n\nif module_path not in sys.path:\n    sys.path.append(module_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:51.732882Z","iopub.execute_input":"2026-01-17T13:54:51.733137Z","iopub.status.idle":"2026-01-17T13:54:51.744739Z","shell.execute_reply.started":"2026-01-17T13:54:51.733116Z","shell.execute_reply":"2026-01-17T13:54:51.743887Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport random\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import datasets\nimport torchvision.transforms.v2 as v2\n\nfrom glgennc.glgenn.algebra.cliffordalgebraex import CliffordAlgebraQT\nfrom glgennc.glgenn.algebra.cliffordalgebra import CliffordAlgebra\nfrom glgennc.glgenn.layers.qtgp import QTGeometricProduct\nfrom glgennc.glgenn.layers.qtlinear import QTLinear\nfrom glgennc.glgenn.layers.qtnorm import QTNormalization\n\nimport matplotlib.pyplot as plt","metadata":{"id":"7a769c04","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:51.745814Z","iopub.execute_input":"2026-01-17T13:54:51.746095Z","iopub.status.idle":"2026-01-17T13:54:52.962324Z","shell.execute_reply.started":"2026-01-17T13:54:51.746067Z","shell.execute_reply":"2026-01-17T13:54:52.961612Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"SEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)","metadata":{"id":"666aa908","outputId":"24df9dca-b5be-4a5a-a7b8-a29e7d624a95","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:52.963350Z","iopub.execute_input":"2026-01-17T13:54:52.963814Z","iopub.status.idle":"2026-01-17T13:54:52.972914Z","shell.execute_reply.started":"2026-01-17T13:54:52.963780Z","shell.execute_reply":"2026-01-17T13:54:52.972118Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x78222eda4630>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Dataloader (Colored Fashion MNIST / CIFAR-10)\n","metadata":{"id":"fff538bc"}},{"cell_type":"code","source":"class CliffordFashionedMnist(Dataset):\n    def __init__(self, root, train=True, download=True, d=3):\n        self.metric = [1] * d\n        self.ca = CliffordAlgebraQT(self.metric)\n        self.d = d\n        self.post_transforms = v2.Compose([\n            v2.ToImage(),\n            v2.ToDtype(torch.float32, scale=True),\n            v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n\n        self.data = datasets.FashionMNIST(root, train=train, download=download)\n        _, self.h, self.w = self.data.data.shape\n        # y_coords, x_coords = torch.meshgrid(\n        #     torch.linspace(-1, 1, self.h),\n        #     torch.linspace(-1, 1, self.w),\n        #     indexing=\"ij\"\n        # )\n        # self.grid = torch.stack([x_coords, y_coords], dim=0) # [2, 28, 28]\n\n    def _colorize_random(self, img):\n        img_np = np.array(img)\n        factors = np.random.uniform(0.2, 1.0, 3)\n        color_img = np.stack([img_np * f for f in factors], axis=-1).astype(np.uint8) # [28, 28, 3]\n        return color_img\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_raw, label = self.data[idx]\n        img_colored = self._colorize_random(img_raw) # [3, 28, 28]\n        img_tensor = self.post_transforms(img_colored)\n        v_full = img_tensor #torch.cat([self.grid, img_tensor], dim=0) # [3, 28, 28]\n        v_full = v_full.permute(1, 2, 0) # [28, 28, 3]\n        return v_full, label","metadata":{"id":"66d67d76","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:52.973897Z","iopub.execute_input":"2026-01-17T13:54:52.974215Z","iopub.status.idle":"2026-01-17T13:54:52.983281Z","shell.execute_reply.started":"2026-01-17T13:54:52.974169Z","shell.execute_reply":"2026-01-17T13:54:52.982492Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision.transforms import v2\n\nclass CliffordCIFAR10(Dataset):\n    def __init__(self, root, train=True, download=True, d=3):\n        self.metric = [1] * d\n        self.ca = CliffordAlgebraQT(self.metric)\n        self.d = d\n        self.post_transforms = v2.Compose([\n            v2.ToImage(),\n            v2.ToDtype(torch.float32, scale=True),\n            v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n\n        self.data = datasets.CIFAR10(root, train=train, download=download)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_raw, label = self.data[idx]\n        img_tensor = self.post_transforms(img_raw) # [3, 32, 32]\n        v_full = img_tensor.permute(1, 2, 0) \n        return v_full, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:52.984345Z","iopub.execute_input":"2026-01-17T13:54:52.984672Z","iopub.status.idle":"2026-01-17T13:54:52.999327Z","shell.execute_reply.started":"2026-01-17T13:54:52.984619Z","shell.execute_reply":"2026-01-17T13:54:52.998460Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Prepare: MVSiLU from CGENN","metadata":{"id":"b263a519"}},{"cell_type":"code","source":"def unsqueeze_like(tensor: torch.Tensor, like: torch.Tensor, dim=0):\n    \"\"\"\n    Unsqueeze last dimensions of tensor to match another tensor's number of dimensions.\n\n    Args:\n        tensor (torch.Tensor): tensor to unsqueeze\n        like (torch.Tensor): tensor whose dimensions to match\n        dim: int: starting dim, default: 0.\n    \"\"\"\n    n_unsqueezes = like.ndim - tensor.ndim\n    if n_unsqueezes < 0:\n        raise ValueError(f\"tensor.ndim={tensor.ndim} > like.ndim={like.ndim}\")\n    elif n_unsqueezes == 0:\n        return tensor\n    else:\n        return tensor[dim * (slice(None),) + (None,) * n_unsqueezes]\n\nclass MVSiLU(nn.Module):\n    def __init__(self, algebra, channels, invariant=\"mag2\", exclude_dual=False):\n        super().__init__()\n        self.algebra = algebra\n        self.channels = channels\n        self.exclude_dual = exclude_dual\n        self.invariant = invariant\n        self.a = nn.Parameter(torch.ones(1, channels, algebra.dim + 1))\n        self.b = nn.Parameter(torch.zeros(1, channels, algebra.dim + 1))\n\n        if invariant == \"norm\":\n            self._get_invariants = self._norms_except_scalar\n        elif invariant == \"mag2\":\n            self._get_invariants = self._mag2s_except_scalar\n        else:\n            raise ValueError(f\"Invariant {invariant} not recognized.\")\n\n    def _norms_except_scalar(self, input):\n        return self.algebra.norms(input, grades=self.algebra.grades[1:])\n\n    def _mag2s_except_scalar(self, input):\n        return self.algebra.qs(input, grades=self.algebra.grades[1:])\n\n    def forward(self, input):\n        norms = self._get_invariants(input)\n        norms = torch.cat([input[..., :1], *norms], dim=-1)\n        a = unsqueeze_like(self.a, norms, dim=2)\n        b = unsqueeze_like(self.b, norms, dim=2)\n        norms = a * norms + b\n        norms = norms.repeat_interleave(self.algebra.subspaces, dim=-1)\n        return torch.sigmoid(norms) * input","metadata":{"id":"a0561b75","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:53.000851Z","iopub.execute_input":"2026-01-17T13:54:53.001078Z","iopub.status.idle":"2026-01-17T13:54:53.013227Z","shell.execute_reply.started":"2026-01-17T13:54:53.001058Z","shell.execute_reply":"2026-01-17T13:54:53.012499Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class CGEBlock(nn.Module):\n    def __init__(self, algebra, in_features, out_features):\n        super().__init__()\n        print(in_features)\n\n        self.layers = nn.Sequential(\n                QTGeometricProduct(algebra, out_features),\n                QTNormalization(algebra, out_features),\n            )\n    def forward(self, input):\n        # [batch_size, in_features, 2**d] -> [batch_size, out_features, 2**d]\n        return self.layers(input)","metadata":{"id":"35f627f4","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:53.014053Z","iopub.execute_input":"2026-01-17T13:54:53.014320Z","iopub.status.idle":"2026-01-17T13:54:53.024862Z","shell.execute_reply.started":"2026-01-17T13:54:53.014296Z","shell.execute_reply":"2026-01-17T13:54:53.024111Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class CGEMLP(nn.Module):\n    def __init__(self, algebra, in_features, hidden_features, out_features, n_layers=2):\n        super().__init__()\n\n        layers = []\n        for i in range(n_layers - 1):\n            layers.append(\n                CGEBlock(algebra, in_features, hidden_features)\n            )\n            in_features = hidden_features\n        layers.append(\n            CGEBlock(algebra, hidden_features, out_features)\n        )\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, input):\n        return self.layers(input)","metadata":{"id":"2cde10ff","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:53.025723Z","iopub.execute_input":"2026-01-17T13:54:53.025926Z","iopub.status.idle":"2026-01-17T13:54:53.034603Z","shell.execute_reply.started":"2026-01-17T13:54:53.025905Z","shell.execute_reply":"2026-01-17T13:54:53.033921Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Model: GLGENN","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nclass CliffordFashionModel(nn.Module):\n    def __init__(self, ca, in_channels, hidden_channels, out_classes):\n        super().__init__()\n        self.ca = ca\n        self.hidden_channels = hidden_channels\n        self.cge_part = CGEMLP(ca, in_channels, hidden_channels, hidden_channels, 2)\n        self.final_norm = QTNormalization(ca, hidden_channels)\n        self.clifford_head = nn.Sequential(\n            QTLinear(ca, in_channels, out_classes)\n        )\n\n    def forward(self, x):\n        x = self.ca.embed_grade(x, 1)\n        batch_size, h, w, mv_dim = x.shape\n        x_processed = x.view(batch_size, h*w, mv_dim)\n        h_out = self.cge_part(x_processed)\n        flat_mvs = h_out.reshape(batch_size, h * w, mv_dim)\n        logits_mv = self.clifford_head(flat_mvs) \n        return logits_mv[..., 0]","metadata":{"id":"6d99d97e","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:54:53.035573Z","iopub.execute_input":"2026-01-17T13:54:53.035849Z","iopub.status.idle":"2026-01-17T13:54:53.046207Z","shell.execute_reply.started":"2026-01-17T13:54:53.035828Z","shell.execute_reply":"2026-01-17T13:54:53.045432Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Training & Evaluating","metadata":{"id":"1ef6d7e8"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nimport torchvision.transforms.functional as TF\nfrom tqdm import tqdm\nimport time\nimport math\n\ndef train(model, train_loader, test_loader, optimizer, criterion, epochs, device):\n    for epoch in range(epochs):\n        model.train()\n        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n        correct = 0\n        total = 0\n        grad_norms = []  \n        \n        for images, labels in pbar:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n\n            # logging gradient norms\n            total_norm = 0.0\n            for p in model.parameters():\n                if p.grad is not None:\n                    param_norm = p.grad.detach().data.norm(2)\n                    total_norm += param_norm.item() ** 2\n            total_norm = total_norm ** 0.5\n            grad_norms.append(total_norm)\n \n            optimizer.step()\n\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n            \n            avg_grad = sum(grad_norms[-10:]) / len(grad_norms[-10:])\n            pbar.set_postfix({\n                'loss': f'{loss.item():.4f}', \n                'acc': f'{100.*correct/total:.2f}%',\n                'grad': f'{avg_grad:.2f}'\n            })\n        model.eval()\n        test_correct = 0\n        rot_correct = 0\n        test_total = 0\n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = outputs.max(1)\n                test_correct += predicted.eq(labels).sum().item()\n                rotated_images = TF.rotate(images, angle=180) \n                outputs_rot = model(rotated_images)\n                _, predicted_rot = outputs_rot.max(1)\n                rot_correct += predicted_rot.eq(labels).sum().item()\n                test_total += labels.size(0)\n        \n        test_acc = 100. * test_correct / test_total\n        rot_acc = 100. * rot_correct / test_total\n        \n        print(f'Epoch {epoch+1}, Inital Accuracy: {test_acc:.2f}%')\n        print(f'Epoch {epoch+1}, Rotated Accuracy: {rot_acc:.2f}%')\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nd = 3\nlr = 0.001\nepochs = 10\nbatch_size = 256\n\nca = CliffordAlgebraQT([1] * d)\nfull_dataset = CliffordCIFAR10(root='./data', train=True, download=True, d=d)\ntest_dataset = CliffordCIFAR10(root='./data', train=False, download=True, d=d)\n\ntrain_loader = DataLoader(\n    full_dataset, \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=4, \n    pin_memory=True          \n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=4, \n    pin_memory=True          \n)\n\nmodel = CliffordFashionModel(ca, in_channels=1024, hidden_channels=1024, out_classes=10).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\n\ntrain(model, train_loader, test_loader, optimizer, criterion, epochs, device)","metadata":{"id":"2fc1e03c","outputId":"a7d30f25-5ad6-4edc-e626-9d29983b6f21","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T14:09:24.545853Z","iopub.execute_input":"2026-01-17T14:09:24.546595Z","iopub.status.idle":"2026-01-17T14:14:55.981336Z","shell.execute_reply.started":"2026-01-17T14:09:24.546564Z","shell.execute_reply":"2026-01-17T14:14:55.980505Z"}},"outputs":[{"name":"stdout","text":"1024\n1024\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 196/196 [00:30<00:00,  6.47it/s, loss=1.7568, acc=35.84%, grad=1.01]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Inital Accuracy: 42.27%\nEpoch 1, Rotated Accuracy: 41.18%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 196/196 [00:29<00:00,  6.62it/s, loss=1.2598, acc=50.12%, grad=1.10]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Inital Accuracy: 45.42%\nEpoch 2, Rotated Accuracy: 43.26%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 196/196 [00:29<00:00,  6.66it/s, loss=1.1106, acc=60.42%, grad=1.14]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Inital Accuracy: 46.33%\nEpoch 3, Rotated Accuracy: 44.87%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 196/196 [00:29<00:00,  6.60it/s, loss=0.8693, acc=70.66%, grad=1.16]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Inital Accuracy: 46.90%\nEpoch 4, Rotated Accuracy: 45.51%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 196/196 [00:29<00:00,  6.64it/s, loss=0.7395, acc=79.33%, grad=1.20]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Inital Accuracy: 47.87%\nEpoch 5, Rotated Accuracy: 45.42%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 196/196 [00:29<00:00,  6.64it/s, loss=0.5575, acc=85.96%, grad=1.09]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Inital Accuracy: 46.93%\nEpoch 6, Rotated Accuracy: 45.03%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 196/196 [00:29<00:00,  6.63it/s, loss=0.3481, acc=90.61%, grad=1.02]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Inital Accuracy: 46.61%\nEpoch 7, Rotated Accuracy: 44.67%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 196/196 [00:29<00:00,  6.63it/s, loss=0.2067, acc=93.53%, grad=0.93]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Inital Accuracy: 46.98%\nEpoch 8, Rotated Accuracy: 44.97%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 196/196 [00:29<00:00,  6.63it/s, loss=0.1418, acc=96.04%, grad=0.76]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Inital Accuracy: 47.18%\nEpoch 9, Rotated Accuracy: 45.18%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 196/196 [00:29<00:00,  6.64it/s, loss=0.2109, acc=97.13%, grad=0.82]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Inital Accuracy: 47.34%\nEpoch 10, Rotated Accuracy: 46.05%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Model: just MLP","metadata":{}},{"cell_type":"code","source":"class SimpleMLP(nn.Module):\n    def __init__(self, in_channels=1, hidden_dim=128, out_classes=10):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        \n        self.model = nn.Sequential(\n            nn.Linear(1024 * in_channels, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, out_classes)\n        )\n    def forward(self, x):\n        out = self.flatten(x)\n        out = self.model(out)\n        return out\n\nmodel = SimpleMLP(in_channels=3, hidden_dim=128).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\ntrain(model, train_loader, test_loader, optimizer, criterion, epochs, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T13:55:01.816590Z","iopub.execute_input":"2026-01-17T13:55:01.817615Z","iopub.status.idle":"2026-01-17T13:56:25.772542Z","shell.execute_reply.started":"2026-01-17T13:55:01.817558Z","shell.execute_reply":"2026-01-17T13:56:25.771774Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 196/196 [00:07<00:00, 27.95it/s, loss=1.6468, acc=41.70%, grad=1.54]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Inital Accuracy: 46.32%\nEpoch 1, Rotated Accuracy: 22.13%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 196/196 [00:06<00:00, 28.16it/s, loss=1.4123, acc=48.82%, grad=1.55]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Inital Accuracy: 49.16%\nEpoch 2, Rotated Accuracy: 23.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 196/196 [00:06<00:00, 28.75it/s, loss=1.1526, acc=52.04%, grad=1.61]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Inital Accuracy: 49.74%\nEpoch 3, Rotated Accuracy: 24.46%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 196/196 [00:06<00:00, 28.25it/s, loss=1.5190, acc=54.14%, grad=1.75]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Inital Accuracy: 50.77%\nEpoch 4, Rotated Accuracy: 25.22%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 196/196 [00:07<00:00, 27.99it/s, loss=1.4575, acc=56.06%, grad=1.73]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Inital Accuracy: 51.94%\nEpoch 5, Rotated Accuracy: 24.46%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 196/196 [00:06<00:00, 28.58it/s, loss=1.1090, acc=57.66%, grad=1.94]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Inital Accuracy: 51.57%\nEpoch 6, Rotated Accuracy: 25.09%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|██████████| 196/196 [00:06<00:00, 28.53it/s, loss=1.3361, acc=58.63%, grad=1.88]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Inital Accuracy: 52.15%\nEpoch 7, Rotated Accuracy: 25.66%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|██████████| 196/196 [00:06<00:00, 28.35it/s, loss=1.0026, acc=60.12%, grad=2.06]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Inital Accuracy: 51.76%\nEpoch 8, Rotated Accuracy: 25.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|██████████| 196/196 [00:06<00:00, 28.17it/s, loss=1.0408, acc=61.11%, grad=1.77]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Inital Accuracy: 51.66%\nEpoch 9, Rotated Accuracy: 24.15%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|██████████| 196/196 [00:06<00:00, 28.33it/s, loss=0.9542, acc=62.11%, grad=1.90]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Inital Accuracy: 52.11%\nEpoch 10, Rotated Accuracy: 24.36%\n","output_type":"stream"}],"execution_count":13}]}